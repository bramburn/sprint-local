{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FileAnalyser Exploration Notebook\n",
    "\n",
    "## Overview\n",
    "This notebook explores the `FileAnalyser` class, which is part of the agent's reflection system. The class is designed to analyze file contents using language models and generate insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\dev\\sprint_app\\sprint-py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('.'),  '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "print(\"Project root:\", project_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Initialization\n",
    "Let's explore how to initialize the `FileAnalyser` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileAnalyser initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from src.agent.reflection.file_analyser import FileAnalyser\n",
    "# Initialize the FileAnalyser\n",
    "file_analyser = FileAnalyser()\n",
    "print(\"FileAnalyser initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Analysis Method\n",
    "The `analyse_file` method is the core functionality of the `FileAnalyser` class. Let's demonstrate its usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Analysis Result:\n",
      "The provided workflow appears to be mostly complete and logical. However, there are a few inconsistencies and improvements that can be made:\n",
      "\n",
      "1. **Code should not reuse a node as both the start and end point**: Nodes `I` and `J` are used as both start and end points, which is contradictory. It would be better to use `I` as the start point and `L` as the end point.\n",
      "\n",
      "2. **The first instance of `process_data` should not return anything**: Since the starting point is `A[Start]`, the first instance of `process_data` is unnecessary. The workflow can start directly from `B[process_data Function]`.\n",
      "\n",
      "3. **Initialize cleaned_data variable**: In the given workflow, `cleaned_data` is created within the `process_data` function using a list comprehension. However, this variable is only accessible within the `process_data` function. To separate the clean_data creation from the calculation, we could create `cleaned_data` before passing it to `calculate_total`. \n",
      "\n",
      "Here's a revised version of the workflow diagram:\n",
      "\n",
      "```mermaid\n",
      "flowchart TD\n",
      "    A[Start] --> B[Process Data]\n",
      "    B --> C[Filter out None values from data]\n",
      "    C --> E{Conditional to handle None values}\n",
      "    E -->|Is None value| F[None values removed]\n",
      "    F --> G[Cleaned_data]\n",
      "    G --> H[Pass cleaned_data to calculate_total]\n",
      "    H --> I[Calculate total]\n",
      "    I --> J[Return total]\n",
      "    J --> I[End]\n",
      "```\n",
      "\n",
      "Here is the revised function analysis for the `calculate_total` and `process_data` functions:\n",
      "\n",
      "```python\n",
      "def calculate_total(items):\n",
      "    \"\"\"Calculate the total of a list of integers.\"\"\"\n",
      "    total = 0\n",
      "    for item in items:\n",
      "        if item is not None:\n",
      "            total += item\n",
      "    return total\n",
      "\n",
      "def process_data(data):\n",
      "    \"\"\"Calculate the total of non-None values in a list.\"\"\"\n",
      "    cleaned_data = [item for item in data if item is not None]\n",
      "    return calculate_total(cleaned_data)\n",
      "```\n",
      "\n",
      "In the revised function analysis, the function `calculate_total` takes in a list of items. It attempts to sum the list, but it only includes values that are not `None`. In the `process_data` function, it uses list comprehension to separate `None` values from the list before passing it to `calculate_total`. This allows the `calculate_total` function to handle the sum without directly processing the potentially `None` values.\n"
     ]
    }
   ],
   "source": [
    "# Example file content for analysis\n",
    "sample_file_content = \"\"\"\n",
    "def calculate_total(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total += item\n",
    "    return total\n",
    "\n",
    "def process_data(data):\n",
    "    cleaned_data = [x for x in data if x is not None]\n",
    "    return calculate_total(cleaned_data)\n",
    "\"\"\"\n",
    "\n",
    "# Analyze the file content\n",
    "analysis_result = file_analyser.analyse_file(sample_file_content)\n",
    "print(\"File Analysis Result:\")\n",
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling and Edge Cases\n",
    "Let's explore potential error scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with empty content\n",
    "try:\n",
    "    empty_analysis = file_analyser.analyse_file(\"\")\n",
    "    print(\"Empty content analysis:\")\n",
    "    print(empty_analysis)\n",
    "except Exception as e:\n",
    "    print(f\"Error handling empty content: {e}\")\n",
    "\n",
    "# Test with None input\n",
    "try:\n",
    "    none_analysis = file_analyser.analyse_file(None)\n",
    "    print(\"None content analysis:\")\n",
    "    print(none_analysis)\n",
    "except Exception as e:\n",
    "    print(f\"Error handling None input: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Workflow Inspection\n",
    "Let's explore the internal workflow of the `FileAnalyser`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the workflow components\n",
    "print(\"Step One Analyse Workflow:\")\n",
    "print(file_analyser.step_one_analyse_workflow)\n",
    "\n",
    "print(\"\\nStep Two Analyse Mermaid Workflow:\")\n",
    "print(file_analyser.step_two_analyse_mermaid_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook demonstrates the key functionalities of the `FileAnalyser` class, including initialization, file analysis, and workflow inspection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint-py-aqV3NLOV-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
