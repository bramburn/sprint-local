{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reflection chain initialized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.agent.reflection.reflection_chain import ReflectionChain\n",
    "\n",
    "load_dotenv()\n",
    "vector_store_path = r\"C:\\dev\\sprint_app\\sprint-py\\vector_store\\test\"\n",
    "chain = ReflectionChain()\n",
    "print(\"reflection chain initialized\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "problem_description = \"\"\"\n",
    "\n",
    "add multiple vector stores to the reflection chain for documentation for the backlog in reflection_chain.py.\n",
    "it shouldn't affect the current vectore store that we're using to get data context for the backlog.\n",
    "this will be additional vector stores for documentation this means a new entry to the backlog.md file and backlog_step_two.md file.\n",
    "we don't need to analyse the files in the documentation vector stores, so we just need to get the snippets from the vector stores. and provide it as context by  merging them and providing it as context.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running reflection chain\n"
     ]
    }
   ],
   "source": [
    "print(\"running reflection chain\")\n",
    "result = chain.reflect(problem_description, vector_store_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use\n",
    "\n",
    "1. Modify the `problem_description` variable to test different scenarios\n",
    "2. Adjust the `number_of_tests` variable to simulate different test case counts\n",
    "3. Run all cells to see the reflection chain output\n",
    "4. The output will show the complete reflection process including:\n",
    "   - Initial problem analysis\n",
    "   - Test case evaluation\n",
    "   - Self-evaluation\n",
    "   - Refined analysis\n",
    "   - Final aggregation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint-py-aqV3NLOV-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
